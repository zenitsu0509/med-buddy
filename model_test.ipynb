{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"E:\\GIT REPOS\\medince project\\med-buddy\\model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_path, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the uses of Avastin 400mg Injection?\"\n",
    "context = (\n",
    "    \"Medicine Name: Avastin 400mg Injection, Composition: Bevacizumab (400mg), \"\n",
    "    \"Uses: Cancer of colon and rectum, lung cancer, \"\n",
    "    \"Side Effects: Headache, taste change, rectal bleeding.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(question, context, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = torch.argmax(outputs.start_logits)\n",
    "end_idx = torch.argmax(outputs.end_logits) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: \n"
     ]
    }
   ],
   "source": [
    "answer = tokenizer.decode(inputs['input_ids'][0][start_idx:end_idx])\n",
    "print(f\"Predicted Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Logits: tensor([[-0.1499, -0.1050,  0.1103,  0.0493,  0.3222,  0.3714,  0.0520,  0.1403,\n",
      "          0.4226,  0.5431,  0.5296,  0.5341,  0.1696,  0.0548,  0.3024,  0.4558,\n",
      "          0.2566,  0.1700,  0.1141,  0.4547,  0.6932,  0.6101,  0.5417,  0.0686,\n",
      "          0.9289,  0.4252,  0.1260,  0.4536,  0.2801,  0.3606,  0.2495,  0.3393,\n",
      "          0.5158,  0.5089,  0.1970,  0.0103,  0.5431,  0.2496,  0.2542, -0.1486,\n",
      "          0.0701,  0.1334, -0.0592,  0.0798,  0.0738,  0.7213,  0.4316,  0.0027,\n",
      "          0.7830,  0.6705,  0.3746,  0.3940,  0.0643,  0.6962,  0.5311, -0.0060,\n",
      "          0.0193,  0.2015,  0.4584,  0.2024,  0.1988]])\n",
      "End Logits: tensor([[ 0.3382,  0.3404,  0.1317,  0.7138,  0.2258,  0.3969, -0.4776, -0.0068,\n",
      "          0.2653, -0.0376, -0.0650, -0.3285,  0.0165,  0.3406,  0.4519, -0.1019,\n",
      "          0.1917, -0.5239,  0.0577,  0.2431, -0.1050, -0.0995, -0.5261,  0.2504,\n",
      "         -0.1272,  0.0108, -0.1609, -0.2845, -0.2267,  0.1251,  0.2155, -0.0015,\n",
      "          0.0242, -0.3168,  0.3921,  0.3167,  0.0371,  0.2163, -0.0131,  0.1682,\n",
      "         -0.0163,  0.0262,  0.0550, -0.2836,  0.0097, -0.0111, -0.2197,  0.2658,\n",
      "          0.5053, -0.1840,  0.0574, -0.0023,  0.0048, -0.1736, -0.0129, -0.0680,\n",
      "          0.3414, -0.1310, -0.1345,  0.3917,  0.4000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Logits:\", outputs.start_logits)\n",
    "print(\"End Logits:\", outputs.end_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  101,  2054,  2024,  1996,  3594,  1997, 10927, 16643,  2078,  4278,\n",
      "         24798, 13341,  1029,   102,  4200,  2171,  1024, 10927, 16643,  2078,\n",
      "          4278, 24798, 13341,  1010,  5512,  1024,  2022, 24887, 10993, 12248,\n",
      "          2497,  1006,  4278, 24798,  1007,  1010,  3594,  1024,  4456,  1997,\n",
      "         16844,  1998, 28667, 11667,  1010, 11192,  4456,  1010,  2217,  3896,\n",
      "          1024, 14978,  1010,  5510,  2689,  1010, 28667,  9080,  9524,  1012,\n",
      "           102]])\n",
      "Tokens: ['[CLS]', 'what', 'are', 'the', 'uses', 'of', 'ava', '##sti', '##n', '400', '##mg', 'injection', '?', '[SEP]', 'medicine', 'name', ':', 'ava', '##sti', '##n', '400', '##mg', 'injection', ',', 'composition', ':', 'be', '##vac', '##iz', '##uma', '##b', '(', '400', '##mg', ')', ',', 'uses', ':', 'cancer', 'of', 'colon', 'and', 'rec', '##tum', ',', 'lung', 'cancer', ',', 'side', 'effects', ':', 'headache', ',', 'taste', 'change', ',', 'rec', '##tal', 'bleeding', '.', '[SEP]']\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs:\", inputs['input_ids'])\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))\n",
    "print(\"Attention Mask:\", inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid answer range detected.\n",
      "Predicted Answer: \n"
     ]
    }
   ],
   "source": [
    "start_idx = torch.argmax(outputs.start_logits, dim=1).item()\n",
    "end_idx = torch.argmax(outputs.end_logits, dim=1).item() + 1\n",
    "\n",
    "# Handle cases where start_idx >= end_idx\n",
    "if start_idx >= end_idx:\n",
    "    print(\"Invalid answer range detected.\")\n",
    "    answer = \"\"\n",
    "else:\n",
    "    answer = tokenizer.decode(inputs['input_ids'][0][start_idx:end_idx])\n",
    "print(f\"Predicted Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Start Logit: tensor(0.9289)\n",
      "Max End Logit: tensor(0.7138)\n",
      "Min Start Logit: tensor(-0.1499)\n",
      "Min End Logit: tensor(-0.5261)\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Start Logit:\", torch.max(outputs.start_logits))\n",
    "print(\"Max End Logit:\", torch.max(outputs.end_logits))\n",
    "print(\"Min Start Logit:\", torch.min(outputs.start_logits))\n",
    "print(\"Min End Logit:\", torch.min(outputs.end_logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Start Probability: 0.029939182102680206\n",
      "Max End Probability: 0.030901720747351646\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "start_probs = F.softmax(outputs.start_logits, dim=1)\n",
    "end_probs = F.softmax(outputs.end_logits, dim=1)\n",
    "\n",
    "max_start_prob = torch.max(start_probs).item()\n",
    "max_end_prob = torch.max(end_probs).item()\n",
    "\n",
    "print(f\"Max Start Probability: {max_start_prob}\")\n",
    "print(f\"Max End Probability: {max_end_prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: No confident answer found.\n"
     ]
    }
   ],
   "source": [
    "start_idx = torch.argmax(start_probs, dim=1).item()\n",
    "end_idx = torch.argmax(end_probs, dim=1).item() + 1\n",
    "\n",
    "if start_idx < end_idx and max_start_prob > 0.1 and max_end_prob > 0.1:\n",
    "    answer = tokenizer.decode(inputs['input_ids'][0][start_idx:end_idx])\n",
    "else:\n",
    "    answer = \"No confident answer found.\"\n",
    "\n",
    "print(f\"Predicted Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
